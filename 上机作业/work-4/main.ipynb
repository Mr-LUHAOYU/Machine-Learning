{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 波士顿房价预测任务（线性回归、岭回归实现）\n",
    "\n",
    "包括数据准备、模型训练、模型评估与选择、性能度量、参数选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 问题背景与数据集介绍\n",
    "\n",
    "波士顿房价预测是一个经典的机器学习任务，类似于程序员世界的“Hello World”。和大家对房价的普遍认知相同，波士顿地区的房价受诸多因素影响。美国某经济杂志登出波士顿房价数据集，该数据集包含506条观测信息，统计了13种可能影响房价的因素（输入变量）和该类型房屋的均价（输出变量），其中每条观测信息包含城镇犯罪率、一氧化氮浓度、住宅平均房间数、到中心区域的加权距离以及自住房平均房价等关于波士顿周边或者城镇房价的描述，期望通过分析影响波士顿房价的因素来构建房价预测模型。相关属性描述如下图所示，其中最后一项就是想要预测的房屋均价。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/be005522b4c441ba89ee7a2ad8277f7c8706457a7a8e4b5f84f92591a32b701d)\n",
    "\n",
    "\n",
    "观测数据的示例如下图所示。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/46fb2e80de2047ff8af2c16819a9e3f5114533f01e3c44c697cfdd66be7bf22f)\n",
    "\n",
    "\n",
    "\n",
    "对于预测问题，可以根据预测输出的类型是连续的实数值，还是离散的标签，区分为回归任务和分类任务。因为房价是一个连续值，所以房价预测显然是一个回归任务。本次实验要求大家调用sklearn 的线性回归、岭回归模型来实现。\n",
    "\n",
    "### 实现过程：\n",
    "1. 数据准备：导入数据、特征可视化\n",
    "2. 数据预处理：数据集划分、数据标准化处理\n",
    "3. 模型训练：线性回归、岭回归\n",
    "4. 模型评估与选择、参数选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据准备\n",
    "\n",
    "### 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-03-12T05:09:35.190477300Z",
     "start_time": "2024-03-12T05:09:35.176459Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\n`load_boston` has been removed from scikit-learn since version 1.2.\n\nThe Boston housing prices dataset has an ethical problem: as\ninvestigated in [1], the authors of this dataset engineered a\nnon-invertible variable \"B\" assuming that racial self-segregation had a\npositive impact on house prices [2]. Furthermore the goal of the\nresearch that led to the creation of this dataset was to study the\nimpact of air quality but it did not give adequate demonstration of the\nvalidity of this assumption.\n\nThe scikit-learn maintainers therefore strongly discourage the use of\nthis dataset unless the purpose of the code is to study and educate\nabout ethical issues in data science and machine learning.\n\nIn this special case, you can fetch the dataset from the original\nsource::\n\n    import pandas as pd\n    import numpy as np\n\n    data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n    raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n    data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n    target = raw_df.values[1::2, 2]\n\nAlternative datasets include the California housing dataset and the\nAmes housing dataset. You can load the datasets as follows::\n\n    from sklearn.datasets import fetch_california_housing\n    housing = fetch_california_housing()\n\nfor the California housing dataset and::\n\n    from sklearn.datasets import fetch_openml\n    housing = fetch_openml(name=\"house_prices\", as_frame=True)\n\nfor the Ames housing dataset.\n\n[1] M Carlisle.\n\"Racist data destruction?\"\n<https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8>\n\n[2] Harrison Jr, David, and Daniel L. Rubinfeld.\n\"Hedonic housing prices and the demand for clean air.\"\nJournal of environmental economics and management 5.1 (1978): 81-102.\n<https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air>\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdatasets\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m load_boston\n\u001B[0;32m      2\u001B[0m boston \u001B[38;5;241m=\u001B[39m load_boston()\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(boston\u001B[38;5;241m.\u001B[39mDESCR)\n",
      "File \u001B[1;32mD:\\Python\\Lib\\site-packages\\sklearn\\datasets\\__init__.py:156\u001B[0m, in \u001B[0;36m__getattr__\u001B[1;34m(name)\u001B[0m\n\u001B[0;32m    105\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mload_boston\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    106\u001B[0m     msg \u001B[38;5;241m=\u001B[39m textwrap\u001B[38;5;241m.\u001B[39mdedent(\n\u001B[0;32m    107\u001B[0m \u001B[38;5;250m        \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    108\u001B[0m \u001B[38;5;124;03m        `load_boston` has been removed from scikit-learn since version 1.2.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;124;03m        \"\"\"\u001B[39;00m\n\u001B[0;32m    155\u001B[0m     )\n\u001B[1;32m--> 156\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(msg)\n\u001B[0;32m    157\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    158\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mglobals\u001B[39m()[name]\n",
      "\u001B[1;31mImportError\u001B[0m: \n`load_boston` has been removed from scikit-learn since version 1.2.\n\nThe Boston housing prices dataset has an ethical problem: as\ninvestigated in [1], the authors of this dataset engineered a\nnon-invertible variable \"B\" assuming that racial self-segregation had a\npositive impact on house prices [2]. Furthermore the goal of the\nresearch that led to the creation of this dataset was to study the\nimpact of air quality but it did not give adequate demonstration of the\nvalidity of this assumption.\n\nThe scikit-learn maintainers therefore strongly discourage the use of\nthis dataset unless the purpose of the code is to study and educate\nabout ethical issues in data science and machine learning.\n\nIn this special case, you can fetch the dataset from the original\nsource::\n\n    import pandas as pd\n    import numpy as np\n\n    data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n    raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n    data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n    target = raw_df.values[1::2, 2]\n\nAlternative datasets include the California housing dataset and the\nAmes housing dataset. You can load the datasets as follows::\n\n    from sklearn.datasets import fetch_california_housing\n    housing = fetch_california_housing()\n\nfor the California housing dataset and::\n\n    from sklearn.datasets import fetch_openml\n    housing = fetch_openml(name=\"house_prices\", as_frame=True)\n\nfor the Ames housing dataset.\n\n[1] M Carlisle.\n\"Racist data destruction?\"\n<https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8>\n\n[2] Harrison Jr, David, and Daniel L. Rubinfeld.\n\"Hedonic housing prices and the demand for clean air.\"\nJournal of environmental economics and management 5.1 (1978): 81-102.\n<https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据可视化\n",
    "\n",
    "通过观察不同属性与房价之间的关系，分析影响房价的主要因素。\n",
    "\n",
    "boston.data 存储的是所有样本的属性值，boston.target 存储的是所有样本的房价。下段程序所展示的13幅图中，横坐标是该属性的取值，纵坐标是房价值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-03-12T05:09:21.076350800Z",
     "start_time": "2024-03-12T05:09:20.461954700Z"
    }
   },
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[1;32mD:\\Python\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3652\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3651\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3652\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3653\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32mD:\\Python\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mD:\\Python\\Lib\\site-packages\\pandas\\_libs\\index.pyx:153\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: '(slice(None, None, None), 0)' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mInvalidIndexError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m13\u001B[39m):\n\u001B[0;32m      4\u001B[0m     plt\u001B[38;5;241m.\u001B[39msubplot(\u001B[38;5;241m2\u001B[39m,\u001B[38;5;241m7\u001B[39m,i\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m----> 5\u001B[0m     plt\u001B[38;5;241m.\u001B[39mscatter(\u001B[43mboston\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m,boston\u001B[38;5;241m.\u001B[39mtarget,s\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m20\u001B[39m)\n\u001B[0;32m      6\u001B[0m     plt\u001B[38;5;241m.\u001B[39mtitle(boston\u001B[38;5;241m.\u001B[39mfeature_names[i])\n\u001B[0;32m      7\u001B[0m plt\u001B[38;5;241m.\u001B[39msavefig(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimg.png\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32mD:\\Python\\Lib\\site-packages\\pandas\\core\\frame.py:3760\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3758\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   3759\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 3760\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3761\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   3762\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32mD:\\Python\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3659\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3654\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3655\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3656\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3657\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3658\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m-> 3659\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_indexing_error\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3660\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Python\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5736\u001B[0m, in \u001B[0;36mIndex._check_indexing_error\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   5732\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_check_indexing_error\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):\n\u001B[0;32m   5733\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_scalar(key):\n\u001B[0;32m   5734\u001B[0m         \u001B[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001B[39;00m\n\u001B[0;32m   5735\u001B[0m         \u001B[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001B[39;00m\n\u001B[1;32m-> 5736\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n",
      "\u001B[1;31mInvalidIndexError\u001B[0m: (slice(None, None, None), 0)"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 2000x1000 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,10))\n",
    "for i in range(13):\n",
    "    plt.subplot(2,7,i+1)\n",
    "    plt.scatter(boston.data[:,i],boston.target,s=20)\n",
    "    plt.title(boston.feature_names[i])\n",
    "plt.savefig('img.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理\n",
    "### 任务1：数据集划分\n",
    "\n",
    "调用sklearn.model_selection中的train_test_split()函数，把boston数据集分为训练集和测试集，划分比例是4:1。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 补全代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "# X_train,X_test,y_train,y_test = _________\n",
    "X_train,X_test,y_train,y_test = train_test_split(boston.data,boston)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 任务2：数据标准化处理：\n",
    "#### 1. Z-score标准化\n",
    "\n",
    "首先使用StandardScaler()函数初始化对属性值的标准化器，然后调用fit_transform()方法对训练数据进行Z-score标准化，再将这个标准化器调用transform()方法用于测试数据的标准化。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 补全代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# 初始化对属性值的标准化器\n",
    "ss_X = StandardScaler()\n",
    "# ss_X调用fit_transform()和transform()方法对训练数据和测试数据进行标准化\n",
    "X_train = _________\n",
    "X_test = _________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. MinMax标准化\n",
    "\n",
    "首先使用StandardScaler()函数初始化对属性值的标准化器，然后调用fit_transform()方法对训练数据进行Z-score标准化，再将这个标准化器调用transform()方法用于测试数据的标准化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 补全代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# 初始化对属性值的标准化器\n",
    "mm_X = MinMaxScaler()\n",
    "# mm_X调用fit_transform()和transform()方法对训练数据和测试数据进行MinMax标准化\n",
    "X_train1 = _________\n",
    "X_test1 = _________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 模型训练与评估\n",
    "### 任务3.1：线性回归模型训练\n",
    "\n",
    "调用sklearn.linear_model中的LinearRegression()函数，对训练集(X_train,y_train)进行模型训练，并预测测试集X_test的房价lr_y_predict。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 补全代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "#线性回归模型训练\n",
    "__________________\n",
    "#模型预测\n",
    "__________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 任务3.2：线性回归模型评估\n",
    "\n",
    "回归模型常用的三种评价指标：（1）R方分数（决定系数）、（2）MSE均方误差、以及（3）MAE平均绝对误差。\n",
    "\n",
    "方法一：调用sklearn.metrics中的相关函数，计算测试结果lr_y_predict与真实结果y_test之间的误差或精度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\n",
    "print ('the value of R-squared of LR is',r2_score(y_test,lr_y_predict))\n",
    "print ('the MSE of LR is',mean_squared_error(y_test,lr_y_predict))\n",
    "print ('the MAE of LR is',mean_absolute_error(y_test,lr_y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "方法二：自己编写函数，计算上述指标。本实验要求学生至少完成MSE均方误差的计算，并打印输出结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 请在下方作答\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 任务3.3：岭回归模型训练\n",
    "\n",
    "调用sklearn.linear_model中的Ridge()函数(参数设置为5)，对训练集(X_train,y_train)进行模型训练，并预测测试集X_test的房价rd_y_predict。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 补全代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "rd = Ridge(alpha=5)\n",
    "#岭回归模型训练\n",
    "__________________\n",
    "print(rd.coef_)\n",
    "#模型测试\n",
    "__________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 任务3.4：岭回归模型评估\n",
    "\n",
    "与线性回归一样，岭回归模型有两种方法计算评价指标，这里调用sklearn.metrics来实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\n",
    "print('the value of R-squared of Ridge is',r2_score(y_test,rd_y_predict ))\n",
    "print('the MSE of Ridge is',mean_squared_error(y_test,rd_y_predict))\n",
    "print('the MAE of Ridge is',mean_absolute_error(y_test,rd_y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数选择\n",
    "### 任务4：运用交叉验证选择模型参数\n",
    "\n",
    "岭回归模型参数是正则化参数alpha，前面把它设置为5。为了选择最优参数，对训练集进行10次10折交叉验证。具体地，参数选择在[0,10]范围内，以1为步长，进行选择。\n",
    "1. 总共进行11次实验（不同alpha值），每次实验将训练数据随机分成10份，重复10次；\n",
    "2. 每一次划分，任意9份做训练，剩余1份测试，共执行10次，测试结果取平均；\n",
    "3. 再将所有划分的结果再取平均，作为这一次alpha取值的分数；\n",
    "4. 比较不同alpha取值的交叉验证模型分数，来选择其中表现最好的（分数最高的）模型的alpha值；\n",
    "5. 用上述选择的alpha值对训练数据重新训练模型，再测试评估。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 补全代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "cv_score_list = []\n",
    "for i in range(11):\n",
    "    # alpha 取不同值\n",
    "    rd = Ridge(alpha=i)\n",
    "    avg_score_cross = []\n",
    "    # 进行10次随机划分\n",
    "    for j in __________\n",
    "        #调用KFold()实现10折划分\n",
    "        ____________________\n",
    "        #调用cross_val_score()计算训练集本次10折划分的分数\n",
    "        score_cross = ____________________\n",
    "        avg_score_cross.append(np.mean(score_cross))\n",
    "    cv_score_list.append(np.mean(avg_score_cross))\n",
    "\n",
    "plt.plot(range(11), cv_score_list)\n",
    "plt.show()\n",
    "\n",
    "# cv_score_list中找到分数最大的模型所对应的alpha取值\n",
    "____________________\n",
    "rd = Ridge(alpha=index)\n",
    "#岭回归模型训练\n",
    "__________________\n",
    "#模型测试\n",
    "__________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二分类问题\n",
    "### 任务5：波士顿房价二分类问题\n",
    "\n",
    "为了了解分类问题的建模与评估，本任务将连续值的波士顿房价数值使用阈值进行二值化（0,1，例如：廉价房、品质房），可以将房价预测的回归问题，改为简单的二分类问题。\n",
    "\n",
    "同样是包括四个步骤：数据准备、数据预处理、模型训练、模型评估与选择。\n",
    "\n",
    "\n",
    "下面的程序使用方法一调用sklearn.metrics中的相应函数计算预测结果的准确率accuracy、f1 score、auc值。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import matplotlib.pyplot as plt\n",
    "boston = load_boston()\n",
    "# 房价数值二值化\n",
    "threshold = np.mean(boston.target)\n",
    "labels = (boston.target>threshold).astype(np.int_)\n",
    "\n",
    "# 数据集划分\n",
    "X_train,X_test,y_train,y_test = ____________________\n",
    "# 省略数据预处理步骤\n",
    "\n",
    "# 模型训练\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "#线性回归模型训练\n",
    "__________________\n",
    "#模型预测\n",
    "__________________\n",
    "#预测结果二值化\n",
    "lr_y_predict = (lr_y_predict>0.5).astype(np.int_)\n",
    "print(lr_y_predict)\n",
    "\n",
    "# 模型评估\n",
    "from sklearn.metrics import accuracy_score,f1_score,roc_auc_score\n",
    "print('the accuracy score of LR is',__________________)\n",
    "print('the f1 score of LR is',__________________)\n",
    "print('the auc of LR is',__________________)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "方法二：自己编写函数，计算上述指标。\n",
    "\n",
    "本实验要求学生至少完成accuracy与f1 score的计算，并打印输出结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 请在下方作答\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
